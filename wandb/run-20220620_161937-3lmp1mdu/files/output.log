task  :  decnet-completion
network_model  :  enet2021
mode  :  train
dataset  :  nn
workers  :  4
epochs  :  100
criterion  :  l2
batch_size  :  1
learning_rate  :  1e-06
weight_decay  :  1e-06
print_freq  :  10
resume  :
data_folder  :  /datasets
convolutional_layer_encoding  :  xyz
dilation_rate  :  2
val_h  :  352
val_w  :  608
min_depth_eval  :  0.1
max_depth_eval  :  80.0
kitti_crop  :  eigen_crop
train_datalist  :  train_dim_kitti.list
val_datalist  :  val_dim_kitti.list
root_folder  :  data/kitti_dataset/val_selection_cropped/
torch_mode  :  pytorch
wandblogger  :  False
project  :  depth
entity  :  wandbdimar
STEP 2. Loading datasets...
Loaded 600 training files
Loaded 400 val files
STEP 3. Loading model and metrics...
Loaded model enet2021 for decnet-completion
STEP 4. Training or eval stage...
STEP. Training block...
sparse_shape_before torch.Size([8, 1, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])
  4%|███████▊                                                                                                                                                                                            | 3/75 [00:01<00:34,  2.06it/s]
sparse_shape_before torch.Size([8, 1, 352, 608])
  7%|█████████████                                                                                                                                                                                       | 5/75 [00:02<00:37,  1.85it/s]
Traceback (most recent call last):
  File "main.py", line 432, in <module>
    training_block()
  File "main.py", line 395, in training_block
    optimizer.step()
  File "/home/dim/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torch/optim/lr_scheduler.py", line 65, in wrapper
    return wrapped(*args, **kwargs)
  File "/home/dim/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torch/optim/optimizer.py", line 88, in wrapper
    return func(*args, **kwargs)
  File "/home/dim/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torch/autograd/grad_mode.py", line 28, in decorate_context
    return func(*args, **kwargs)
  File "/home/dim/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torch/optim/adam.py", line 144, in step
    eps=group['eps'])
  File "/home/dim/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torch/optim/_functional.py", line 94, in adam
    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)
KeyboardInterrupt