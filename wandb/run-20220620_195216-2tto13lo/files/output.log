task  :  decnet-completion
network_model  :  enet2021
mode  :  train
dataset  :  nn
workers  :  4
epochs  :  100
criterion  :  l2
batch_size  :  1
learning_rate  :  1e-06
weight_decay  :  1e-06
print_freq  :  10
resume  :
data_folder  :  /datasets
convolutional_layer_encoding  :  xyz
dilation_rate  :  2
val_h  :  352
val_w  :  608
min_depth_eval  :  0.1
max_depth_eval  :  80.0
kitti_crop  :  eigen_crop
train_datalist  :  train_dim_kitti.list
val_datalist  :  val_dim_kitti.list
root_folder  :  data/kitti_dataset/val_selection_cropped/
torch_mode  :  pytorch
wandblogger  :  False
project  :  depth
entity  :  wandbdimar
STEP 2. Loading datasets...
Loaded 600 training files
Loaded 400 val files
  8%|███████████████▌                                                                                                                                                                                  | 32/400 [00:01<00:15, 23.01it/s]
STEP 3. Loading model and metrics...
Loaded model enet2021 for decnet-completion
STEP 4. Training or eval stage...
STEP. Testing block...
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 1e-06
    lr: 1e-06
    weight_decay: 0







 89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                     | 356/400 [00:15<00:01, 23.53it/s]
400.0
Results:
d1  =  0.7585431462526322
d2  =  0.9379052580893039
d3  =  0.9823841486871242
abs_rel  =  0.15202249184250832
sq_rel  =  1.0831725265085697
rmse  =  6.275847437381745
rmse_log  =  0.22666663445532323
log10  =  0.07266388801857829
silog  =  0.20579138258472085
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [00:17<00:00, 22.77it/s]
  0%|                                                                                                                                                                                                            | 0/75 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "main.py", line 476, in <module>
    training_block()
  File "main.py", line 371, in training_block
    image, gt, sparse = transform_to_tensor(image), transform_to_tensor(gt), transform_to_tensor(sparse)
  File "/home/dim/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torchvision/transforms/transforms.py", line 98, in __call__
    return F.to_tensor(pic)
  File "/home/dim/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torchvision/transforms/functional.py", line 117, in to_tensor
    raise ValueError('pic should be 2/3 dimensional. Got {} dimensions.'.format(pic.ndim))
ValueError: pic should be 2/3 dimensional. Got 4 dimensions.