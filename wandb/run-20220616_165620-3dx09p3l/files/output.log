task  :  decnet-completion
network_model  :  enet2021
mode  :  train
dataset  :  nn
workers  :  4
epochs  :  20
criterion  :  l2
batch_size  :  1
learning_rate  :  1e-05
weight_decay  :  1e-06
print_freq  :  10
resume  :
data_folder  :  /datasets
convolutional_layer_encoding  :  xyz
dilation_rate  :  2
val_h  :  352
val_w  :  608
min_depth_eval  :  0.1
max_depth_eval  :  80.0
kitti_crop  :  eigen_crop
train_datalist  :  train_dim_kitti.list
val_datalist  :  val_dim_kitti.list
root_folder  :  data/kitti_dataset/val_selection_cropped/
wandblogger  :  False
project  :  depth
entity  :  wandbdimar
STEP 2. Loading datasets...
Loaded 600 training files
Loaded 400 val files
STEP 3. Loading model and metrics...
  9%|█████▊                                                         | 37/400 [00:01<00:16, 21.80it/s]
Loaded model enet2021 for decnet-completion
STEP 4. Training or eval stage...








 98%|█████████████████████████████████████████████████████████████ | 394/400 [00:17<00:00, 22.32it/s]
400.0
Results:
d1  =  0.8627962327003479
d2  =  0.9612934863567353
d3  =  0.9886573822796345
abs_rel  =  0.10718738820403814
sq_rel  =  0.7758614541776478
rmse  =  5.2193673402071
rmse_log  =  0.17142250591889024
log10  =  0.04784376933705062
silog  =  0.16539725314825773
100%|██████████████████████████████████████████████████████████████| 400/400 [00:18<00:00, 22.02it/s]
  0%|                                                                        | 0/400 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "main.py", line 365, in <module>
    training_block()
  File "main.py", line 311, in training_block
    inv_pred =  model(image)
  File "/home/dim/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/dim/depth_2022/models/guide_depth.py", line 44, in forward
    y = self.feature_extractor(x)
  File "/home/dim/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/dim/depth_2022/models/guide_ddrnet.py", line 349, in forward
    self.spp(self.layer5(self.relu(x))),
  File "/home/dim/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/dim/depth_2022/models/guide_ddrnet.py", line 191, in forward
    x_list.append(self.process4((F.interpolate(self.scale4(x),
  File "/home/dim/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/dim/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/dim/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/dim/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py", line 179, in forward
    self.eps,
  File "/home/dim/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torch/nn/functional.py", line 2280, in batch_norm
    _verify_batch_size(input.size())
  File "/home/dim/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torch/nn/functional.py", line 2248, in _verify_batch_size
    raise ValueError("Expected more than 1 value per channel when training, got input size {}".format(size))
ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 512, 1, 1])