task  :  decnet-completion
network_model  :  enet2021
mode  :  train
dataset  :  nn
workers  :  4
epochs  :  100
criterion  :  l2
batch_size  :  1
learning_rate  :  1e-06
weight_decay  :  1e-06
print_freq  :  10
resume  :
data_folder  :  /datasets
convolutional_layer_encoding  :  xyz
dilation_rate  :  2
val_h  :  352
val_w  :  608
min_depth_eval  :  0.1
max_depth_eval  :  80.0
kitti_crop  :  eigen_crop
train_datalist  :  train_dim_kitti.list
val_datalist  :  val_dim_kitti.list
root_folder  :  data/kitti_dataset/val_selection_cropped/
torch_mode  :  pytorch
wandblogger  :  False
project  :  depth
entity  :  wandbdimar
STEP 2. Loading datasets...
Loaded 600 training files
Loaded 400 val files
  8%|███████████████▌                                                                                                                                                                                  | 32/400 [00:01<00:18, 19.95it/s]
STEP 3. Loading model and metrics...
Loaded model enet2021 for decnet-completion
STEP 4. Training or eval stage...
STEP. Testing block...
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 1e-06
    lr: 1e-06
    weight_decay: 0
)
dict_keys(['file', 'rgb', 'd', 'gt'])
dict_keys(['file', 'rgb', 'd', 'gt'])
dict_keys(['file', 'rgb', 'd', 'gt'])
dict_keys(['file', 'rgb', 'd', 'gt'])
dict_keys(['file', 'rgb', 'd', 'gt'])
dict_keys(['file', 'rgb', 'd', 'gt'])
dict_keys(['file', 'rgb', 'd', 'gt'])
dict_keys(['file', 'rgb', 'd', 'gt'])
dict_keys(['file', 'rgb', 'd', 'gt'])
dict_keys(['file', 'rgb', 'd', 'gt'])
dict_keys(['file', 'rgb', 'd', 'gt'])
dict_keys(['file', 'rgb', 'd', 'gt'])
dict_keys(['file', 'rgb', 'd', 'gt'])
dict_keys(['file', 'rgb', 'd', 'gt'])
dict_keys(['file', 'rgb', 'd', 'gt'])
dict_keys(['file', 'rgb', 'd', 'gt'])
dict_keys(['file', 'rgb', 'd', 'gt'])
dict_keys(['file', 'rgb', 'd', 'gt'])
dict_keys(['file', 'rgb', 'd', 'gt'])
dict_keys(['file', 'rgb', 'd', 'gt'])
dict_keys(['file', 'rgb', 'd', 'gt'])
dict_keys(['file', 'rgb', 'd', 'gt'])
dict_keys(['file', 'rgb', 'd', 'gt'])
dict_keys(['file', 'rgb', 'd', 'gt'])
dict_keys(['file', 'rgb', 'd', 'gt'])
dict_keys(['file', 'rgb', 'd', 'gt'])
dict_keys(['file', 'rgb', 'd', 'gt'])
dict_keys(['file', 'rgb', 'd', 'gt'])
dict_keys(['file', 'rgb', 'd', 'gt'])
dict_keys(['file', 'rgb', 'd', 'gt'])
dict_keys(['file', 'rgb', 'd', 'gt'])
dict_keys(['file', 'rgb', 'd', 'gt'])
dict_keys(['file', 'rgb', 'd', 'gt'])
dict_keys(['file', 'rgb', 'd', 'gt'])
dict_keys(['file', 'rgb', 'd', 'gt'])
dict_keys(['file', 'rgb', 'd', 'gt'])
dict_keys(['file', 'rgb', 'd', 'gt'])
dict_keys(['file', 'rgb', 'd', 'gt'])
dict_keys(['file', 'rgb', 'd', 'gt'])
dict_keys(['file', 'rgb', 'd', 'gt'])
dict_keys(['file', 'rgb', 'd', 'gt'])
dict_keys(['file', 'rgb', 'd', 'gt'])
dict_keys(['file', 'rgb', 'd', 'gt'])
dict_keys(['file', 'rgb', 'd', 'gt'])
dict_keys(['file', 'rgb', 'd', 'gt'])
dict_keys(['file', 'rgb', 'd', 'gt'])
 12%|██████████████████████▊                                                                                                                                                                           | 47/400 [00:02<00:19, 18.42it/s]
Traceback (most recent call last):
  File "main.py", line 408, in <module>
    evaluation_block()
  File "main.py", line 186, in evaluation_block
    for i, data in enumerate(tqdm(test_dl)):
  File "/home/dim/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/tqdm/std.py", line 1180, in __iter__
    for obj in iterable:
  File "/home/dim/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/home/dim/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 561, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/dim/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 49, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/dim/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 49, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/dim/depth_2022/features/decnet_dataloaders.py", line 74, in __getitem__
    transformed_data_sample = self.data_transform(file_id, rgb, sparse, gt)
  File "/home/dim/depth_2022/features/decnet_dataloaders.py", line 61, in data_transform
    transformed_rgb = transform(rgb).to('cuda')
  File "/home/dim/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torchvision/transforms/transforms.py", line 61, in __call__
    img = t(img)
  File "/home/dim/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torchvision/transforms/transforms.py", line 184, in __call__
    return F.to_pil_image(pic, self.mode)
  File "/home/dim/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torchvision/transforms/functional.py", line 308, in to_pil_image
    return Image.fromarray(npimg, mode=mode)
  File "/home/dim/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/PIL/Image.py", line 2856, in fromarray
    return frombuffer(mode, size, obj, "raw", rawmode, 0, 1)
  File "/home/dim/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/PIL/Image.py", line 2796, in frombuffer
    return frombytes(mode, size, data, decoder_name, args)
  File "/home/dim/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/PIL/Image.py", line 2742, in frombytes
    im.frombytes(data, decoder_name, args)
  File "/home/dim/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/PIL/Image.py", line 807, in frombytes
    s = d.decode(data)
KeyboardInterrupt