task  :  decnet-completion
network_model  :  enet2021
mode  :  eval
dataset  :  nn
workers  :  4
epochs  :  100
criterion  :  l2
batch_size  :  1
learning_rate  :  0.001
weight_decay  :  1e-06
print_freq  :  10
resume  :
data_folder  :  /datasets
convolutional_layer_encoding  :  xyz
dilation_rate  :  2
val_h  :  352
val_w  :  608
min_depth_eval  :  0.1
max_depth_eval  :  80.0
kitti_crop  :  eigen_crop
datalist  :  datalist_val_kitti.list
root_folder  :  data/kitti_dataset/val_selection_cropped/
wandblogger  :  False
project  :  depth
entity  :  wandbdimar
STEP 2. Loading datasets...
<torch.utils.data.dataloader.DataLoader object at 0x7fea39c9b250>
Loaded 1000 test files
STEP 3. Loading model and metrics...
Loaded model enet2021 for decnet-completion
STEP 4. Training or eval stage...
  0%|                                                                       | 0/1000 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "main.py", line 197, in <module>
    inv_pred =  model(image)#image.permute(0,2,3,1))
  File "/home/dim/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/dim/depth_2022/models/guide_depth.py", line 44, in forward
    y = self.feature_extractor(x)
  File "/home/dim/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/dim/depth_2022/models/guide_ddrnet.py", line 317, in forward
    x = self.conv1(x)
  File "/home/dim/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/dim/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/dim/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/dim/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 446, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/dim/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 608, 384, 1280] to have 3 channels, but got 608 channels instead