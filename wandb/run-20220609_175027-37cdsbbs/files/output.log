STEP 2. Loading datasets...
<torch.utils.data.dataloader.DataLoader object at 0x7fe8cd5ab390>
Loaded 1000 test files
STEP 3. Loading model and metrics...
Loaded model enet2021 for decnet-completion
STEP 4. Training or eval stage...
Currently on image 0 out of 1000
Mean values per iter: {'d1': 0.9983936548233032, 'd2': 0.9994803071022034, 'd3': 0.9997637867927551, 'abs_rel': 0.012011617422103882, 'sq_rel': 0.017657756805419922, 'rmse': 0.7395699620246887, 'rmse_log': 0.024964358657598495, 'log10': 0.005166057497262955, 'silog': 0.024963390082120895}
Currently on image 1 out of 1000
Traceback (most recent call last):
  File "main.py", line 103, in <module>
    _, _, pred =  model(data)
  File "/home/dim/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/dim/depth_2022/models/enet_pro.py", line 151, in forward
    rgb_feature3 = self.rgb_encoder_layer3(rgb_feature2, geo_s2, geo_s3) # b 64 88 304
  File "/home/dim/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/dim/depth_2022/models/enet_basic.py", line 317, in forward
    out = torch.cat((g2,out), 1)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 7.80 GiB total capacity; 2.44 GiB already allocated; 82.00 MiB free; 2.46 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF