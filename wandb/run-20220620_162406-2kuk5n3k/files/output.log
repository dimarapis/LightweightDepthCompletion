
  0%|                                                                                                                                                                                                            | 0/75 [00:00<?, ?it/s]
task  :  decnet-completion
network_model  :  enet2021
mode  :  train
dataset  :  nn
workers  :  4
epochs  :  100
criterion  :  l2
batch_size  :  1
learning_rate  :  1e-06
weight_decay  :  1e-06
print_freq  :  10
resume  :
data_folder  :  /datasets
convolutional_layer_encoding  :  xyz
dilation_rate  :  2
val_h  :  352
val_w  :  608
min_depth_eval  :  0.1
max_depth_eval  :  80.0
kitti_crop  :  eigen_crop
train_datalist  :  train_dim_kitti.list
val_datalist  :  val_dim_kitti.list
root_folder  :  data/kitti_dataset/val_selection_cropped/
torch_mode  :  pytorch
wandblogger  :  False
project  :  depth
entity  :  wandbdimar
STEP 2. Loading datasets...
Loaded 600 training files
Loaded 400 val files

  4%|███████▊                                                                                                                                                                                            | 3/75 [00:01<00:35,  2.02it/s]
Loaded model enet2021 for decnet-completion
STEP 4. Training or eval stage...
STEP. Training block...
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])

 11%|████████████████████▉                                                                                                                                                                               | 8/75 [00:03<00:30,  2.22it/s]
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])

 16%|███████████████████████████████▏                                                                                                                                                                   | 12/75 [00:05<00:27,  2.26it/s]
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])

 23%|████████████████████████████████████████████▏                                                                                                                                                      | 17/75 [00:07<00:25,  2.27it/s]
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])

 28%|██████████████████████████████████████████████████████▌                                                                                                                                            | 21/75 [00:09<00:23,  2.27it/s]
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])

 35%|███████████████████████████████████████████████████████████████████▌                                                                                                                               | 26/75 [00:11<00:21,  2.26it/s]
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])

 40%|██████████████████████████████████████████████████████████████████████████████                                                                                                                     | 30/75 [00:13<00:19,  2.26it/s]
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])

 47%|███████████████████████████████████████████████████████████████████████████████████████████                                                                                                        | 35/75 [00:15<00:17,  2.24it/s]
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])


 59%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                | 44/75 [00:19<00:13,  2.24it/s]
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])

 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                      | 48/75 [00:21<00:12,  2.21it/s]
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])


 76%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                              | 57/75 [00:25<00:08,  2.18it/s]
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])

 81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                    | 61/75 [00:27<00:06,  2.17it/s]
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])

 88%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                       | 66/75 [00:29<00:04,  2.17it/s]
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])

 93%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████             | 70/75 [00:31<00:02,  2.17it/s]
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])

 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍  | 74/75 [00:33<00:00,  2.16it/s]
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
sparse_shape_before torch.Size([8, 1, 352, 608])
rgbshape torch.Size([8, 3, 352, 608])
STEP. Testing block...
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 1e-06
    lr: 1e-06
    weight_decay: 0
)
sparse_shape_before torch.Size([1, 352, 608])
sparse_shape_afta torch.Size([1, 1, 352, 608])
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 75/75 [00:34<00:00,  2.21it/s]
  0%|                                                                                                                                                                                                           | 0/400 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "main.py", line 435, in <module>
    training_block()
  File "main.py", line 426, in training_block
    evaluation_block()
  File "main.py", line 237, in evaluation_block
    inv_pred = model(image,sparse)
  File "/home/dim/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/dim/depth_2022/models/sparse_guided_depth.py", line 50, in forward
    y = self.up_1(x_quarter, y)
  File "/home/dim/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/dim/depth_2022/models/guide_modules.py", line 90, in forward
    xy = torch.cat([x, y], dim=1)
RuntimeError: Sizes of tensors must match except in dimension 1. Expected size 96 but got size 88 for tensor number 1 in the list.